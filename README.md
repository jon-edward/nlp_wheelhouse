# nlp_wheelhouse
This is a collection of useful NLP tools as Python wheels built for a Windows isolated environment.

## Installation
Wheels are separated into multiple zipped directories. Go to [Releases](https://github.com/jon-edward/nlp_wheelhouse/releases) 
and download whichever wheel directories fit your use case. 

If you chose `data_wheels.zip` then extract the zip file and run 
`python -m pip install --no-index --find-links=data_wheels -r requirements.txt`, where there exists 
a `requirements.txt` that specifies the required packages from the wheel directory (see 
[`wheel_requirements/`](https://github.com/jon-edward/nlp_wheelhouse/tree/main/wheel_requirements)
to determine which packages are provided by each zip file). 

Note that you can provide multiple paths to `--find-links`, which allows you to combine wheel 
directories if needed.

## Adding a library
New libraries can be added to the appropriate `*_requirements.txt` file in 
[`wheel_requirements/`](https://github.com/jon-edward/nlp_wheelhouse/tree/main/wheel_requirements), 
or an entirely new wheels zip file can be generated by creating a new `*_requirements.txt` file 
if needed.

## Adding spaCy models
SpaCy models are usually downloaded through `python -m spacy download <model>`, but in an isolated environment
this option isn't available. 

SpaCy uses pip to download models, so we can instead add a GitHub link to a build requirements file where we want 
a spaCy model available like:

```
https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1.tar.gz#egg=en_core_web_sm
```

If you want the `en_core_web_sm` model available in your isolated environment, you can instead add the line 
`en_core_web_sm==3.7.1` to your environment's requirements file after following the steps in Installation. 
SpaCy will be able to load and import the model like normal.
